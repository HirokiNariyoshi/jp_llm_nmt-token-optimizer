"""
Test: Can we save tokens by translating Japaneseâ†’English for English-optimized models?
"""

import tiktoken
from deep_translator import GoogleTranslator

def count_tokens(text: str, encoding_name: str = "cl100k_base") -> int:
    """Count tokens using tiktoken (GPT-4/Claude tokenizer)"""
    encoding = tiktoken.get_encoding(encoding_name)
    return len(encoding.encode(text))

# Test prompts in Japanese (common use case in Japan)
japanese_prompts = [
    # Short technical query
    """é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
    æ­´å²çš„ãªç™ºå±•ã€ä¸»è¦ãªå®Ÿé¨“ã€æ•°å­¦çš„åŸºç¤ã€
    é‡å­è¨ˆç®—ã¨æš—å·åŒ–ã«ãŠã‘ã‚‹å®Ÿç”¨çš„ãªå¿œç”¨ã‚’å«ã‚ã¦ãã ã•ã„ã€‚""",
    
    # Medium conversational query
    """æ¥æœˆã€è¦ªå‹ã®ã‚µãƒ—ãƒ©ã‚¤ã‚ºãƒãƒ¼ã‚¹ãƒ‡ãƒ¼ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã‚’ä¼ç”»ã—ã¦ã„ã¾ã™ã€‚
    å½¼å¥³ã¯30æ­³ã«ãªã‚Šã€ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢æ´»å‹•ã€ãƒ´ã‚£ãƒ³ãƒ†ãƒ¼ã‚¸ã®ç¾å­¦ã€
    æ¤ç‰©ã‚„ã‚¬ãƒ¼ãƒ‡ãƒ‹ãƒ³ã‚°ã«é–¢é€£ã™ã‚‹ã“ã¨ãŒå¤§å¥½ãã§ã™ã€‚
    ä»•äº‹ã®ã‚¹ãƒˆãƒ¬ã‚¹ã‚„å€‹äººçš„ãªèª²é¡Œã§å¤§å¤‰ãªä¸€å¹´ã‚’éã”ã—ã¦ããŸã®ã§ã€
    æœ¬å½“ã«ç‰¹åˆ¥ãªã‚‚ã®ã«ã—ãŸã„ã¨æ€ã£ã¦ã„ã¾ã™ã€‚""",
    
    # Long business query
    """å½“ç¤¾ã¯æ–°ã—ã„Eã‚³ãƒãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ç«‹ã¡ä¸Šã’ã‚’è¨ˆç”»ã—ã¦ãŠã‚Šã€
    æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã®é¸æŠã«ã¤ã„ã¦åŠ©è¨€ãŒå¿…è¦ã§ã™ã€‚ç§ãŸã¡ã®ãƒãƒ¼ãƒ ã¯
    Reactã€Node.jsã€Pythonã«ç²¾é€šã—ã¦ã„ã¾ã™ãŒã€è¦æ¨¡æ‹¡å¤§ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿å®ˆæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚ŠãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚
    ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹
    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€APIè¨­è¨ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã¤ã„ã¦
    æ¨å¥¨äº‹é …ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"""
]

print("=" * 80)
print("REVERSE OPTIMIZATION TEST: Japanese â†’ English Translation")
print("=" * 80)
print()

translator = GoogleTranslator(source='ja', target='en')

total_ja_tokens = 0
total_en_tokens = 0

for i, ja_prompt in enumerate(japanese_prompts, 1):
    print(f"\nğŸ“ Test {i}:")
    print(f"Japanese prompt: {ja_prompt[:100]}...")
    
    # Count Japanese tokens
    ja_tokens = count_tokens(ja_prompt)
    
    # Translate to English
    en_prompt = translator.translate(ja_prompt)
    
    # Count English tokens
    en_tokens = count_tokens(en_prompt)
    
    # Calculate savings
    tokens_saved = ja_tokens - en_tokens
    percent_saved = (tokens_saved / ja_tokens * 100) if ja_tokens > 0 else 0
    
    print(f"\n  Japanese tokens: {ja_tokens}")
    print(f"  English tokens:  {en_tokens}")
    print(f"  Tokens saved:    {tokens_saved} ({percent_saved:.1f}%)")
    
    if tokens_saved > 0:
        print(f"  âœ… English is MORE efficient!")
    else:
        print(f"  âŒ Japanese is more efficient")
    
    total_ja_tokens += ja_tokens
    total_en_tokens += en_tokens

print("\n" + "=" * 80)
print("SUMMARY")
print("=" * 80)
total_saved = total_ja_tokens - total_en_tokens
total_percent = (total_saved / total_ja_tokens * 100) if total_ja_tokens > 0 else 0

print(f"\nTotal Japanese tokens: {total_ja_tokens}")
print(f"Total English tokens:  {total_en_tokens}")
print(f"Total tokens saved:    {total_saved} ({total_percent:.1f}%)")
print()

if total_saved > 0:
    print("âœ… VIABLE! Translating Japaneseâ†’English saves tokens!")
    print(f"   For Japanese users, this could reduce costs by {total_percent:.1f}%")
    print()
    print("ğŸ’¡ New Project Direction:")
    print("   'Japanese Query Optimizer for English-Optimized LLMs'")
    print("   JA Input â†’ EN (translate) â†’ LLM â†’ EN â†’ JA (translate)")
else:
    print("âŒ Not viable - Japanese is already more efficient")

print("\n" + "=" * 80)
