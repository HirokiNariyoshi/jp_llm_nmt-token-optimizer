"""
Comprehensive token optimization test with NLLB vs Google Translate
Tests with realistic long prompts to measure actual performance
"""

import time
from token_optimizer import TokenOptimizer
from token_optimizer.translation import GoogleTranslator, NLLBTranslator
import tiktoken

# Realistic test prompts (various lengths)
test_cases = [
    {
        "name": "Long technical documentation",
        "prompt": """
æ—¥æœ¬ã®ä¼æ¥­ãŒæ–°ã—ã„ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã™ã‚‹éš›ã«ã€
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä¸¡ç«‹ã•ã›ã‚‹ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’
è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã«ã¤ã„ã¦ï¼š

1. ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã¨ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®å®Ÿè£…æ–¹æ³•
2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ
3. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®é€šä¿¡ã®æš—å·åŒ–
4. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
5. ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¨CSRFå¯¾ç­–

å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã¨ã¨ã‚‚ã«ã€ãã‚Œãã‚Œã®å®Ÿè£…ã«ãŠã‘ã‚‹æ³¨æ„ç‚¹ã‚‚å«ã‚ã¦æ•™ãˆã¦ãã ã•ã„ã€‚
"""
    },
    {
        "name": "Machine learning explanation",
        "prompt": """
Pythonã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã®ä¸€èˆ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦ã€
åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãæ®µéšçš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ç‰¹ã«ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¦ãã ã•ã„ï¼š
- ãƒ‡ãƒ¼ã‚¿ã®åé›†ã¨å‰å‡¦ç†ã®æ–¹æ³•
- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®é‡è¦æ€§
- ãƒ¢ãƒ‡ãƒ«ã®é¸æŠåŸºæº–
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æ–¹æ³•ã¨éå­¦ç¿’ã®é˜²æ­¢

å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹ä¸»è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆscikit-learnã€pandasã€numpyãªã©ï¼‰
ã«ã¤ã„ã¦ã‚‚è§¦ã‚ŒãªãŒã‚‰ã€å®Ÿè·µçš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""
    },
    {
        "name": "API development guide",
        "prompt": """
RESTful APIã‚’è¨­è¨ˆã™ã‚‹éš›ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ï¼š
- HTTPãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆGETã€POSTã€PUTã€DELETEï¼‰ã®é©åˆ‡ãªä½¿ã„åˆ†ã‘
- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å‘½åè¦å‰‡ã¨URLè¨­è¨ˆ
- ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°æˆ¦ç•¥
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã®ä½¿ã„æ–¹
- èªè¨¼ã¨èªå¯ï¼ˆJWTã€OAuth2.0ãªã©ï¼‰
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆæ–¹æ³•ï¼ˆSwagger/OpenAPIã®æ´»ç”¨ï¼‰

FastAPIã¾ãŸã¯Flaskã‚’ä½¿ç”¨ã—ãŸå®Ÿè£…ä¾‹ã‚‚å«ã‚ã¦ã€å®Ÿè·µçš„ãªå†…å®¹ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
"""
    }
]

def count_tokens(text):
    """Count tokens using tiktoken (cl100k_base encoding)"""
    enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))

def test_comprehensive_optimization():
    """Test full optimization with long prompts"""
    print("=" * 80)
    print("ğŸ”¬ Comprehensive Token Optimization Test: NLLB vs Google Translate")
    print("=" * 80)
    
    # Initialize translators
    try:
        nllb = NLLBTranslator()
        nllb_available = True
        print("âœ… NLLB loaded successfully\n")
    except:
        nllb_available = False
        print("âŒ NLLB not available, using Google only\n")
    
    google = GoogleTranslator()
    
    total_google_savings = 0
    total_nllb_savings = 0
    total_ja_tokens = 0
    
    results = []
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"Test {i}/{len(test_cases)}: {test['name']}")
        print(f"{'='*80}")
        
        prompt = test['prompt'].strip()
        
        # Count Japanese tokens
        ja_tokens = count_tokens(prompt)
        print(f"\nğŸ“ Japanese prompt: {ja_tokens} tokens")
        print(f"   Preview: {prompt[:100]}...")
        
        # Google Translate
        print(f"\nğŸ”µ Google Translate:")
        google_result = google.translate(prompt, "ja", "en")
        google_tokens = count_tokens(google_result.text)
        google_savings = ja_tokens - google_tokens
        google_percent = (google_savings / ja_tokens) * 100
        
        print(f"   English: {google_tokens} tokens")
        print(f"   Savings: {google_savings} tokens ({google_percent:.1f}%)")
        print(f"   Preview: {google_result.text[:100]}...")
        
        # NLLB
        if nllb_available:
            print(f"\nğŸŸ¢ NLLB:")
            nllb_result = nllb.translate(prompt, "ja", "en")
            nllb_tokens = count_tokens(nllb_result.text)
            nllb_savings = ja_tokens - nllb_tokens
            nllb_percent = (nllb_savings / ja_tokens) * 100
            
            print(f"   English: {nllb_tokens} tokens")
            print(f"   Savings: {nllb_savings} tokens ({nllb_percent:.1f}%)")
            print(f"   Preview: {nllb_result.text[:100]}...")
            
            # Comparison
            improvement = nllb_tokens - google_tokens
            improvement_percent = (improvement / google_tokens) * 100
            
            print(f"\nğŸ“Š NLLB vs Google:")
            print(f"   Token difference: {improvement} tokens")
            print(f"   NLLB is {abs(improvement_percent):.1f}% {'more concise' if improvement < 0 else 'more verbose'}")
            
            total_nllb_savings += nllb_savings
            
            results.append({
                "name": test['name'],
                "ja_tokens": ja_tokens,
                "google_tokens": google_tokens,
                "google_savings": google_savings,
                "google_percent": google_percent,
                "nllb_tokens": nllb_tokens,
                "nllb_savings": nllb_savings,
                "nllb_percent": nllb_percent
            })
        
        total_google_savings += google_savings
        total_ja_tokens += ja_tokens
    
    # Summary
    print(f"\n{'='*80}")
    print("ğŸ“Š OVERALL RESULTS")
    print(f"{'='*80}")
    
    print(f"\nTotal Japanese tokens: {total_ja_tokens}")
    
    avg_google_percent = (total_google_savings / total_ja_tokens) * 100
    print(f"\nğŸ”µ Google Translate:")
    print(f"   Total savings: {total_google_savings} tokens")
    print(f"   Average reduction: {avg_google_percent:.1f}%")
    
    if nllb_available:
        avg_nllb_percent = (total_nllb_savings / total_ja_tokens) * 100
        print(f"\nğŸŸ¢ NLLB:")
        print(f"   Total savings: {total_nllb_savings} tokens")
        print(f"   Average reduction: {avg_nllb_percent:.1f}%")
        
        additional_savings = total_nllb_savings - total_google_savings
        print(f"\nâœ¨ NLLB Improvement:")
        print(f"   Additional savings: {additional_savings} tokens")
        print(f"   {avg_nllb_percent - avg_google_percent:.1f} percentage points better")
    
    # Conservative recommendation
    print(f"\n{'='*80}")
    print("ğŸ’¡ CONSERVATIVE PERFORMANCE ESTIMATES")
    print(f"{'='*80}")
    
    if nllb_available:
        # Use the lowest result as conservative estimate
        min_nllb_percent = min(r['nllb_percent'] for r in results)
        max_nllb_percent = max(r['nllb_percent'] for r in results)
        
        print(f"\nBased on testing with realistic long prompts (100+ tokens):")
        print(f"  Minimum savings: {min_nllb_percent:.0f}%")
        print(f"  Maximum savings: {max_nllb_percent:.0f}%")
        print(f"  Average savings: {avg_nllb_percent:.0f}%")
        print(f"\nâœ… Conservative claim: {min_nllb_percent:.0f}-{avg_nllb_percent:.0f}% token reduction")
        print(f"   (Use in documentation)")
        
        return {
            "min_savings": min_nllb_percent,
            "max_savings": max_nllb_percent,
            "avg_savings": avg_nllb_percent,
            "conservative_range": f"{min_nllb_percent:.0f}-{avg_nllb_percent:.0f}%"
        }

if __name__ == "__main__":
    print("\nğŸ§ª Running comprehensive token optimization test...\n")
    print("âš ï¸  This will take several minutes (NLLB translation is slow on CPU)\n")
    
    try:
        results = test_comprehensive_optimization()
        
        if results:
            print(f"\n{'='*80}")
            print("âœ… Test Complete!")
            print(f"{'='*80}")
            print(f"\nğŸ“ Recommended documentation claim:")
            print(f"   'Achieves {results['conservative_range']} token reduction'")
            print(f"   'on realistic prompts (100+ tokens)'")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test interrupted by user")
    except Exception as e:
        print(f"\n\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
